\documentclass{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{pdfpages}

\graphicspath{{./LatexImg/}}

\begin{document}
	
	\includepdf{CoverPage.pdf}
	
	First and foremost, the programming language used to conduct this lab is Python 3.7, and the libraries primarily used are opencv2, numpy, and matplotlib. To view the cover page if it doesn't display properly, open \textbf{CoverPage.pdf} included in the folder provided.\\
	
	\section{Introduction}
	
	This lab examines the concept of artistic stylization and the different ways to produce post-processing images through certain filters and algorithms. The filters produced in this lab are effects that look unnatural. The two main concepts that will be discussed in this lab are the \textbf{eXtended Difference of Gaussians (XDOG)} and the \textbf{Cartoon Effect}.\\
	
	\section{Stylization Effects}
	
	\subsection{eXtended Difference of Gaussian}
	
	The eXtended Difference of Gaussian filter is a simple tool that uses second-order derivative filtering and thresholding.\\
	
	The first step in XDOG, is to find difference between two Gaussian blurred images, one with a standard deviation of $\sigma$, and the other is a scaled version, $k\sigma$, and the sum between that difference with the unscaled Gaussian blurred image. The equation below describes the XDOG filter:\\
	
	\begin{equation}
	D_{\sigma,k,p}(x,y) = (1 + p)G_{\sigma}(x,y) - pG_{k\sigma}(x,y)
	\end{equation}\\
	
	The $k$ term describes the second image's blurring kernel coefficient that controls the level of blur. The only restriction of k is that it is a positive real number, k $>$ 0. The $p$ term describes the potency of the Difference of Gaussian; a higher value means that the difference part affects the original blur more. The values of p have no set range, however if the value exceeds a certain point, the values may experience overflow, thus ruining the intended output. The equation can be rearranged by factoring the values influenced by $p$ in equation 1 to show a more clear definition of the XDOG filter:\\
	
	\begin{equation}
	D_{\sigma,k,p}(x,y) = G_{\sigma}(x,y) + p(G_{\sigma}(x,y) - G_{k\sigma}(x,y) ) 
	\end{equation}\\
	
	By rearranging the equation, it is clear to see that the effect of this filter is a unsharp mask. The only main difference between this process and a normal unsharp mask is that the image is blurred initially, and then the edge image, the difference part of Gaussian, is added back to provide the edge details of the image.\\
	
	The next and final step is to threshold the image to produce the output image. Two methods were implemented in this lab, they can be referred to as hard and soft thresholding.\\
	
	Hard thresholding uses a threshold value, and sets any intensity value less than or equal to the value to 0 and any value greater than to 1. The equation below displays the definition:\\
	
	\begin{equation}
	T(u) = \begin{cases} 
	1, & u > \epsilon\\
	0, & u \leq \epsilon
	\end{cases} 
	\end{equation}\\
	
	Soft Thresholding behaves slightly differently to the hard threshold, where there can be only two values for hard thresholding, there is a transistion between 0 and 1 for the soft thresholding method. This method uses the hyperbolic tangent function to determine the output value of the image if it less than the threshold value.\\
	
	 \begin{equation}
	 T_{\phi}(u) = \begin{cases} 
	 1, & u > \epsilon\\
	 1 + tanh(\phi(u - \epsilon)), & u \leq \epsilon
	 \end{cases} 
	 \end{equation}\\
	
	The value, $\epsilon $ controls the sharpness of the transition between the 0 and 1 value.\\ 
	
	\subsection{Cartoon Effect}
	
	A non-organic filter that adds an effect to a digital image that gives the appearance of an image that has been painted by smearing and giving an effect of mixing colours. Additional effects can be added by adding the edges, the difference of Gaussians part, onto the effect described earlier, to finalize the stylization.
	
	\section{Assignment}
	
	\subsection{XDOG}
	
	\subsubsection{XDOG Kernel}
	
	The eXtended Difference of Gaussians filter implementation follows the same guidelines as equation 1 and 2 and the descriptions above. The following filter is strictly a grayscale filter and any coloured images are converted at the beginning the code below.\\
		
	\noindent \# eXtended Difference of Gaussian\\
	\noindent def XDOG(img, k, sigma, p):\\
	\\
	\indent img\textunderscore temp = img.copy()\\
	\\
	\indent \#    Check for RGB image, if so then convert to grayscale\\
	\indent if img\textunderscore temp.ndim == 3:\\
	\indent \indent img\textunderscore temp = cv2.cvtColor(img\textunderscore temp, cv2.COLOR\textunderscore BGR2GRAY)\\
	\\
	\indent img\textunderscore temp = np.array(img\textunderscore temp, np.double)\\
	\\
	\indent \#    Creation of the gaussian kernels\\
	\indent gauss\textunderscore 1 = gaussian\textunderscore kernel(sigma, 2)\\		\indent gauss\textunderscore 2 = gaussian\textunderscore kernel(k * sigma, 2)\\
	\\
	\indent gauss\textunderscore 1\textunderscore sum = np.sum(gauss\textunderscore 1)\\
	\indent gauss\textunderscore 2\textunderscore sum = np.sum(gauss\textunderscore 2)\\
	\\
	\indent \#    Both gaussian kernels are applied to the image\\
	\indent G1 = bf.spatial\textunderscore filter(img\textunderscore temp, \indent gauss\textunderscore 1 / gauss\textunderscore 1\textunderscore sum)\\
	\indent G2 = bf.spatial\textunderscore filter(img\textunderscore temp, \indent gauss\textunderscore 2 / gauss\textunderscore 2\textunderscore sum)\\
	\\
	\indent \#    Difference of Gaussian Computation\\
	\indent img\textunderscore temp[:,:] = (1 + p) * G1[:,:] - p * G2[:,:]\\
	\\
	\indent return np.array(img\textunderscore temp, np.uint8)\\
		
	These are the input and output images for various values of k, p, and $\sigma$:\\
		
	\begin{center}
		\noindent \includegraphics[scale=0.75]{lena}\\
		Image 1: Input Image\\
			
		\includegraphics[scale=0.75]{s211o}\\
		Image 2: Output Image\\
	\end{center}

	\subsubsection{Threshold}
		
	The hard and soft threshold functions found in equations 3 and 4 are implemented below. The images below differ from the equations described above as they are not binary images, but images that range across the unsigned 8-bit spectrum.\\
		
	\smallskip	
	
	\noindent \textbf{Soft Thresholding}\\
		
	\noindent \# Produces binary threshold image\\
	\noindent def hard\textunderscore threshold(img, cutoff):\\
	\\
	\indent out = np.zeros\textunderscore like(img)\\
	\\
	\indent \# applies the max value to the intensities greater than the cutoff\\
	\indent out[img $>$ cutoff] = 255\\
	\\	
	\indent return out\\
	
	Output images for the images produced in the XDOG filter above.\\
	
	\begin{center}
		\noindent \includegraphics[scale=0.75]{nms-test}\\
		Image 3: Input Image\\
		
		\includegraphics[scale=0.75]{s212ox}\\
		Image 4: Output Image, Horizontal\\
		
		\includegraphics[scale=0.75]{s212oy}\\
		Image 5: Output Image, Vertical\\
	\end{center}
	
	\smallskip
	
	\textbf{Soft Threshold}\\
	
	\noindent \# Implements a soft thresholding function\\
	def soft\textunderscore thereshold(img, cutoff, phi):\\
	\\
	\indent out = np.array(np.ones\textunderscore like(img), np.double)\\
	\\
	\indent \# apply the threshold function\\
	\indent out[img <= cutoff] = 1 + np.tanh(phi * (img[i][j]) - cutoff)\\
	\\
	\indent return np.array( out * 255, np.uint8)\\
	
	Output images for the images produced in the XDOG filter above.\\
	
	\begin{center}
		\noindent \includegraphics[scale=0.75]{nms-test}\\
		Image 3: Input Image\\
		
		\includegraphics[scale=0.75]{s212ox}\\
		Image 4: Output Image, Horizontal\\
		
		\includegraphics[scale=0.75]{s212oy}\\
		Image 5: Output Image, Vertical\\
	\end{center}
	
	\subsection{Three-Tone Operator}
	
	For the three tone generator, the same method that was in the soft thresholding was applied to this operator. Instead of the hyperbolic tangent function being applied when the threshold wasn't exceeded, the function is applied globally. The code for the function is shown below:\\
	
	\noindent \# Three tone generator\\
	\noindent def three\textunderscore tone(img, cutoff, phi):\\
	\\
	\indent out = np.array(np.ones\textunderscore like (img), np.double)\\
	\\
	\indent for i in range(0, len(img)):\\
	\indent \indent for j in range(0, len(img[i])):\\
	\\
	\indent \indent \indent out[i][j] = 1 + np.tanh(phi * (img[i][j] - cutoff) )\\
	\\
	\indent return np.array( (out * 127) + 1, np.uint8)\\
	
	Output images for the images produced in the XDOG filter above.\\
	
	\begin{center}
		\noindent \includegraphics[scale=0.75]{nms-test}\\
		Image 3: Input Image\\
		
		\includegraphics[scale=0.75]{s212ox}\\
		Image 4: Output Image, Horizontal\\
		
		\includegraphics[scale=0.75]{s212oy}\\
		Image 5: Output Image, Vertical\\
	\end{center}
	
	\subsection{Oilify Filter}
	
	Need to add.
	
	\subsection{Cartoon Effect}
	
	\subsubsection{Edge Preserving, Smoothing Area Filter}
	
	This filter was implemented to smooth out the image, to produce a cartoon blur effect while preserving the edges. This filter was achieved by using a median filter and expanding the dimensions of the kernel every iteration.\\
	
	\noindent def edge\textunderscore preserving(img, min\textunderscore window\textunderscore size, iteration):\\
	\\
	\indent out\textunderscore img = img.copy()\\
	\\
	\indent \#     Check for RGB image, if so then convert to grayscale\\
	\indent if out\textunderscore img.ndim == 3:   \\      
	\indent \indent out\textunderscore img = cv2.cvtColor(out\textunderscore img, cv2.COLOR\textunderscore BGR2GRAY)\\
	\\
	\indent for i in range(0, iteration):\\
	\indent \indent out\textunderscore img = cv2.medianBlur(out\textunderscore img, min\textunderscore window\textunderscore size + 2 * i)\\
	\\
	\indent return out\textunderscore img\\
	
	The filter produced the following output with the input provided below:\\
	
	\begin{center}
		\noindent \includegraphics[scale=0.75]{lena}\\
		Image 1: Input Image\\
		
		\includegraphics[scale=0.75]{s211o}\\
		Image 2: Output Image\\
	\end{center}
	
	\subsubsection{Edge Detector}
	
	The edge detector utilizes the functions described above to perform the pipeline outlined in the introduction to find the edges of any input images. The edge detector's inputs are an image array, a derivative kernel, an optional threshold value, and a window size for the NMS filter. \\
	
	The first stage of the edge detection is to remove the noise on the image whilst preserving the edges, which is done by using a gaussian filter. Next, the second step in the filter is to use the spatial filter with the kernel and a transposed matrix based of it to produce the horizontal and vertical gradients of the image. Afterwards, the magnitude of the image gradients is found by using equation 1, outlined above. Furthermore, the magnitude is put through the NMS filter to produce two images that outline the possible edges of the original image. Next, both those images are put into the threshold function to discern the strong edges from the weak ones. Finally, the combination of the two images through the inclusive or function unites the two images to produce the final product that displays the edges of the image file.\\
	
	The code for the edge detector is shown below:\\
	
	\noindent def edge\textunderscore detector(img, H, T=0.1, wndsz=5):\\
	\\
	\indent \# Converts the image to a grayscale if it isn't already\\
	\indent if(img.size == 3):\\
	\indent \indent I = cv2.cvtColor(img.copy(), cv2.COLOR\textunderscore BGR2GRAY)\\
	\indent else:\\
	\indent \indent I = img.copy()\\
	\\
	\indent \# Gaussian Kernel to reduce noise\\
	\indent g\textunderscore kernel = np.array([[1, 4, 7, 4, 1],\\
	\indent \indent [4, 20, 33, 20, 4],\\
	\indent \indent [7, 33, 55, 33, 7],\\
	\indent \indent [4, 20, 33, 20, 4],\\
	\indent \indent [1, 4, 7, 4, 1]])\\
	\\
	\indent g\textunderscore sum = np.sum(g\textunderscore kernel)  \\ 
	\\
	\indent \# Gets the transpose of the horizontal kernel to get the vertical kernel\\
	\indent H\textunderscore t = np.transpose(H)\\
	\\
	\indent \# used to reduce noise in the image while preserving edges\\
	\indent I = spatial\textunderscore filter(I, g\textunderscore kernel / g\textunderscore sum) \\ 
	\\
	\indent \# Convolutes the derivative approximation kernels to find the image \\
	\indent \# gradients\\
	\indent I\textunderscore x, I\textunderscore y = spatial\textunderscore filter(I, H), spatial\textunderscore filter(I, H\textunderscore t)\\
	\\
	\indent \# Computes the gradient magnitude\\
	\indent I = np.sqrt(I\textunderscore x**2 + I\textunderscore y**2)\\
	  \\
	\indent \# Suppressing low fluctuations in intensities\\
	\indent I\textunderscore x, I\textunderscore y = non\textunderscore max\textunderscore suppress(I, wndsz, wndsz)\\
	\\
	\indent \# Threshold all small values that indicate weak edges\\
	\indent \# I = image\textunderscore thresholding(np.array(I, np.uint8), T)\\
	\indent I\textunderscore x = image\textunderscore thresholding(np.array(I\textunderscore x, np.uint8), T)\\
	\indent I\textunderscore y = image\textunderscore thresholding(np.array(I\textunderscore y, np.uint8), T)\\
	\\
	\indent max\textunderscore value = np.iinfo(img.dtype).max\\
	\\
	\indent for i in range(0,len(I\textunderscore x)):\\
	\indent \indent for j in range(0, len(I\textunderscore x[i])):\\
	\\
	\indent \indent \indent if I\textunderscore x[i][j] == max\textunderscore value or I\textunderscore y[i][j] == max\textunderscore value:\\
	\indent \indent \indent \indent I[i][j] = max\textunderscore value\\
	\indent \indent \indent else:\\
	\indent \indent \indent I[i][j] = 0\\
	\\
	\indent return I\\
	
	The input image used is the same one in Image 1. The output image is shown below for both default parameters and manual parameters:\\
	
	\begin{center}
		\noindent \includegraphics[scale=0.75]{s22o-def}\\
		Image 10: Output Image, Default Parameters\\
		
		\includegraphics[scale=0.75]{s22o-adj}\\
		Image 11: Output Image, T = 30\%, window size = 7 \\
		
	\end{center}

	\subsection{Derivative Filters}
	
	The Derivative Filter function selects a derivative kernel for a user and outputs it for the user. The selector is given by the user as an input integer between 0 and 3. It has four premade kernels, including:\\
	
	\textbf{Central Difference}\\
	
	\begin{align*}
	h_{x}(x,y) = \left[
	\begin{matrix}
	1 & 0 & -1
	\end{matrix}
	\right]
	\end{align*}\\
	
	\textbf{Forward Difference}\\
	
	\begin{align*}
	h_{x}(x,y) = \left[
	\begin{matrix}
	0 & 1 & -1
	\end{matrix}
	\right]
	\end{align*}\\
	
	\textbf{Prewitt}\\
	
	\begin{align*}
	h_{x}(x,y) = \left[
	\begin{matrix}
	1 & 0 & -1\\
	2 & 0 & -2\\
	1 & 0 & -1
	\end{matrix}
	\right]
	\end{align*}
	
	\textbf{Sobel}\\
	
	\begin{align*}
	h_{x}(x,y) = \left[
	\begin{matrix}
	1 & 0 & -1\\
	2 & 0 & -2\\
	1 & 0 & -1
	\end{matrix}
	\right]
	\end{align*}
	
	The code for the derivative filter function is displayed below:\\
	
	\noindent def derivative\textunderscore kernel(select):\\
	\\
	\indent \# checks for boundary conditions\\
	\indent select = int(select)\\
	\indent if  select $>$ 3 or select $<$ 0:\\
	\indent \indent return 0\\
	\\
	\indent \# selects operation\\
	\indent if select == 0:\\
	\indent \indent h = np.array([1, 0, -1])\\
	\\
	\indent elif select == 1:\\
	\indent \indent h = np.array([0, 1, -1])\\
	\\
	\indent elif select == 2:\\
	\indent \indent h = np.array([[1, 0, -1],\\
	\indent \indent [1, 0, -1],\\
	\indent \indent [1, 0, -1]])\\
	\\
	\indent else:\\
	\indent \indent h = np.array([[1, 0, -1],\\
	\indent \indent [2, 0, -2],\\
	\indent \indent [1, 0, -1]])\\
	\\
	\indent return h\\
	
	The images below represent the different kernels that were used when sent to the edge detector function above with the same input image, except the Sobel kernel as that was done before in the first test.\\
	
		\begin{center}
		\noindent \includegraphics[scale=0.75]{s23o2}\\
		Image 12: Output Image, Prewitt\\
		
	\end{center}
	
	\section{Analysis}
	
	\begin{enumerate}
		\item When a filter is completely separable, the kernel matrix is a called a rank 1. The rank of a matrix is the number of linear independent column or row vectors.\\ 
		
		Since the kernel is separable it means that the convolution operation can be performed by convoluting the vector kernels in a horizontal and vertical manner to emmulate the $N \times N$ matrix. This helps speed up the algorithm by doing less calculations as instead of doing, $N \times N$ operations per pixel, the computer is doing $N + N$ operations due to the amount of pixels being indexed.
		
		\item Applying the NMS filter with two seperate one-dimensional windows enables the horizontal and vertical edges to be better detected by the algorithm as the lines are compared with the changes in intensity in one direction only, as opposed to all directions.\\
		
		When computing the NMS with a two-dimensional filter, the image gradients are compared against the directional changes in all directions. Therefore the edges would be outlined, but they would not look as defined as they appear to be more segmented compared to the previous method described.\\
		
		\begin{center}
			\noindent \includegraphics[scale=0.75]{s22o-2D}\\
			Image 12: Edge Detection, 2D NMS Filter\\
		\end{center}
		
		\item A pre-processing step before implementing the edge detection algorithm is by reducing the noise. As stated above in the implementation used in this lab, the image was subjected to a Gaussian filter to reduce the overall noise in the image, because small unwanted spikes in intensities could cause the filter to accidentally detect that discrepancy as part of an edge.\\
		
		The central and forward difference did not work in the spatial filter function, therefore there cannot be a comparison on the images. 
		
	\end{enumerate}
	
	\clearpage
	
	\section{References}
	
	[1] A. Jana, “Implement Canny edge detector using Python from scratch,” A Developer Diary, 20-May-2019. [Online]. Available: http://www.adeveloperdiary.com/data-science/computer-vision/implement-canny-edge-detector-using-python-from-scratch/. [Accessed: 18-Nov-2019].
	
\end{document}